RTEClassifier
Training classifier...
  ==> Training (100 iterations)

      Iteration    Log Likelihood    Accuracy
      ---------------------------------------
             1          -0.69315        0.512
             2          -0.67675        0.603
             3          -0.66422        0.615
             4          -0.65429        0.617
             5          -0.64635        0.614
             6          -0.63995        0.612
             7          -0.63471        0.612
             8          -0.63039        0.608
             9          -0.62677        0.607
            10          -0.62372        0.607
            11          -0.62113        0.608
            12          -0.61890        0.608
            13          -0.61697        0.608
            14          -0.61530        0.608
            15          -0.61383        0.610
            16          -0.61253        0.610
            17          -0.61138        0.610
            18          -0.61036        0.610
            19          -0.60945        0.610
            20          -0.60863        0.610
            21          -0.60788        0.610
            22          -0.60721        0.611
            23          -0.60660        0.611
            24          -0.60604        0.611
            25          -0.60553        0.612
            26          -0.60506        0.610
            27          -0.60462        0.610
            28          -0.60422        0.610
            29          -0.60385        0.610
            30          -0.60351        0.610
            31          -0.60318        0.611
            32          -0.60288        0.611
            33          -0.60260        0.611
            34          -0.60234        0.611
            35          -0.60209        0.612
            36          -0.60185        0.612
            37          -0.60163        0.612
            38          -0.60142        0.612
            39          -0.60123        0.612
            40          -0.60104        0.612
            41          -0.60086        0.612
            42          -0.60069        0.612
            43          -0.60053        0.612
            44          -0.60037        0.612
            45          -0.60022        0.612
            46          -0.60008        0.612
            47          -0.59995        0.612
            48          -0.59982        0.612
            49          -0.59969        0.612
            50          -0.59957        0.612
            51          -0.59946        0.611
            52          -0.59935        0.611
            53          -0.59924        0.611
            54          -0.59913        0.611
            55          -0.59903        0.611
            56          -0.59894        0.611
            57          -0.59884        0.611
            58          -0.59875        0.611
            59          -0.59867        0.611
            60          -0.59858        0.612
            61          -0.59850        0.612
            62          -0.59842        0.612
            63          -0.59834        0.612
            64          -0.59827        0.612
            65          -0.59819        0.612
            66          -0.59812        0.612
            67          -0.59805        0.612
            68          -0.59799        0.612
            69          -0.59792        0.612
            70          -0.59786        0.612
            71          -0.59779        0.612
            72          -0.59773        0.612
            73          -0.59767        0.612
            74          -0.59762        0.612
            75          -0.59756        0.612
            76          -0.59751        0.612
            77          -0.59745        0.612
            78          -0.59740        0.612
            79          -0.59735        0.612
            80          -0.59730        0.612
            81          -0.59725        0.612
            82          -0.59720        0.612
            83          -0.59715        0.612
            84          -0.59711        0.612
            85          -0.59706        0.612
            86          -0.59702        0.612
            87          -0.59698        0.612
            88          -0.59693        0.612
            89          -0.59689        0.612
            90          -0.59685        0.612
            91          -0.59681        0.612
            92          -0.59677        0.612
            93          -0.59673        0.612
            94          -0.59670        0.612
            95          -0.59666        0.612
            96          -0.59662        0.612
            97          -0.59659        0.612
            98          -0.59655        0.612
            99          -0.59652        0.612
         Final          -0.59648        0.612
Testing classifier...
Accuracy: 0.5592
length of train tweets 8
length of test tweets 2
  ==> Training (100 iterations)

      Iteration    Log Likelihood    Accuracy
      ---------------------------------------
             1          -0.69315        0.625
             2          -0.43828        1.000
             3          -0.32255        1.000
             4          -0.25509        1.000
             5          -0.21087        1.000
             6          -0.17966        1.000
             7          -0.15646        1.000
             8          -0.13855        1.000
             9          -0.12430        1.000
            10          -0.11270        1.000
            11          -0.10307        1.000
            12          -0.09496        1.000
            13          -0.08802        1.000
            14          -0.08203        1.000
            15          -0.07680        1.000
            16          -0.07219        1.000
            17          -0.06810        1.000
            18          -0.06446        1.000
            19          -0.06118        1.000
            20          -0.05821        1.000
            21          -0.05552        1.000
            22          -0.05307        1.000
            23          -0.05083        1.000
            24          -0.04876        1.000
            25          -0.04686        1.000
            26          -0.04510        1.000
            27          -0.04347        1.000
            28          -0.04195        1.000
            29          -0.04053        1.000
            30          -0.03921        1.000
            31          -0.03797        1.000
            32          -0.03681        1.000
            33          -0.03571        1.000
            34          -0.03468        1.000
            35          -0.03370        1.000
            36          -0.03278        1.000
            37          -0.03191        1.000
            38          -0.03108        1.000
            39          -0.03030        1.000
            40          -0.02955        1.000
            41          -0.02884        1.000
            42          -0.02816        1.000
            43          -0.02752        1.000
            44          -0.02690        1.000
            45          -0.02631        1.000
            46          -0.02575        1.000
            47          -0.02520        1.000
            48          -0.02469        1.000
            49          -0.02419        1.000
            50          -0.02371        1.000
            51          -0.02325        1.000
            52          -0.02281        1.000
            53          -0.02238        1.000
            54          -0.02197        1.000
            55          -0.02158        1.000
            56          -0.02119        1.000
            57          -0.02083        1.000
            58          -0.02047        1.000
            59          -0.02013        1.000
            60          -0.01979        1.000
            61          -0.01947        1.000
            62          -0.01916        1.000
            63          -0.01886        1.000
            64          -0.01857        1.000
            65          -0.01828        1.000
            66          -0.01801        1.000
            67          -0.01774        1.000
            68          -0.01748        1.000
            69          -0.01723        1.000
            70          -0.01699        1.000
            71          -0.01675        1.000
            72          -0.01652        1.000
            73          -0.01629        1.000
            74          -0.01608        1.000
            75          -0.01586        1.000
            76          -0.01566        1.000
            77          -0.01545        1.000
            78          -0.01526        1.000
            79          -0.01506        1.000
            80          -0.01488        1.000
            81          -0.01470        1.000
            82          -0.01452        1.000
            83          -0.01434        1.000
            84          -0.01417        1.000
            85          -0.01401        1.000
            86          -0.01385        1.000
            87          -0.01369        1.000
            88          -0.01353        1.000
            89          -0.01338        1.000
            90          -0.01323        1.000
            91          -0.01309        1.000
            92          -0.01295        1.000
            93          -0.01281        1.000
            94          -0.01267        1.000
            95          -0.01254        1.000
            96          -0.01241        1.000
            97          -0.01228        1.000
            98          -0.01216        1.000
            99          -0.01204        1.000
         Final          -0.01192        1.000
######################
1 Step Classifier :  RTEClassifier
Accuracy :  0.5
######################
   0.882 neg_l(50th)==0.0 and label is 4
   0.882 neg_l(follow)==0.0 and label is 4
   0.882 neg_r(50th)==0.0 and label is 4
   0.882 neg_r(follow)==0.0 and label is 4
   0.882 has(50th)==1 and label is 4
   0.882 has(follow)==1 and label is 4
   0.622 neg_l(still)==0.0 and label is 0
   0.622 neg_l(pour)==0.0 and label is 0
   0.622 neg_l(outsid)==0.0 and label is 0
   0.622 neg_r(still)==0.0 and label is 0
   0.622 neg_r(pour)==0.0 and label is 0
   0.622 neg_r(outsid)==0.0 and label is 0
   0.622 has(still)==1 and label is 0
   0.622 has(pour)==1 and label is 0
   0.622 has(outsid)==1 and label is 0
   0.465 neg_l(proud)==0.0 and label is 4
   0.465 neg_l(best)==0.0 and label is 4
   0.465 neg_l(friend)==0.0 and label is 4
   0.465 neg_l(varsiti)==0.0 and label is 4
   0.465 neg_r(proud)==0.0 and label is 4
   0.465 neg_r(best)==0.0 and label is 4
   0.465 neg_r(friend)==0.0 and label is 4
   0.465 neg_r(varsiti)==0.0 and label is 4
   0.465 has(proud)==1 and label is 4
   0.465 has(best)==1 and label is 4
   0.465 has(friend)==1 and label is 4
   0.465 has(varsiti)==1 and label is 4
   0.353 neg_l(pina)==0.0 and label is 4
   0.353 neg_l(colada)==0.0 and label is 4
   0.353 neg_l(good)==0.0 and label is 4
   0.353 neg_l(for)==0.0 and label is 4
   0.353 neg_l(sore)==0.0 and label is 4
   0.353 neg_l(throat)==0.0 and label is 4
   0.353 neg_r(pina)==0.0 and label is 4
   0.353 neg_r(colada)==0.0 and label is 4
   0.353 neg_r(sore)==0.0 and label is 4
   0.353 neg_r(throat)==0.0 and label is 4
   0.353 has(pina)==1 and label is 4
   0.353 has(colada)==1 and label is 4
   0.353 has(sore)==1 and label is 4
   0.353 has(throat)==1 and label is 4
   0.339 neg_l(__hndl)==0.0 and label is 4
   0.339 neg_r(__hndl)==0.0 and label is 4
   0.339 has(__hndl)==1 and label is 4
   0.331 neg_l(hate)==0.0 and label is 0
   0.331 neg_l(wierd)==0.0 and label is 0
   0.331 neg_l(unknown)==0.0 and label is 0
   0.331 neg_l(thing)==0.0 and label is 0
   0.331 neg_l(move)==0.0 and label is 0
   0.331 neg_l(around)==0.0 and label is 0
   0.331 neg_l(night)==0.0 and label is 0
   0.331 neg_r(hate)==0.0 and label is 0
   0.331 neg_r(wierd)==0.0 and label is 0
   0.331 neg_r(unknown)==0.0 and label is 0
   0.331 neg_r(thing)==0.0 and label is 0
   0.331 neg_r(move)==0.0 and label is 0
   0.331 neg_r(around)==0.0 and label is 0
   0.331 neg_r(night)==0.0 and label is 0
   0.331 has(hate)==1 and label is 0
   0.331 has(wierd)==1 and label is 0
   0.331 has(unknown)==1 and label is 0
   0.331 has(thing)==1 and label is 0
   0.331 has(move)==1 and label is 0
   0.331 has(around)==1 and label is 0
   0.331 has(night)==1 and label is 0
  -0.245 neg_l(__punc_ellp)==0.0 and label is 4
  -0.245 has(__punc_ellp)==1 and label is 4
   0.221 neg_l(neb)==0.0 and label is 0
   0.221 neg_l(treatment)==0.0 and label is 0
   0.221 neg_l(number)==0.0 and label is 0
   0.221 neg_l(thi)==0.0 and label is 0
   0.221 neg_l(even)==0.0 and label is 0
   0.221 neg_l(isnt)==1.0 and label is 0
   0.221 neg_l(look)==0.9 and label is 0
   0.221 neg_l(good)==0.8 and label is 0
   0.221 neg_l(for)==0.7000000000000001 and label is 0
   0.221 neg_l(zoie)==0.6000000000000001 and label is 0
   0.221 neg_r(neb)==0.30000000000000016 and label is 0
   0.221 neg_r(treatment)==0.40000000000000013 and label is 0
   0.221 neg_r(number)==0.5000000000000001 and label is 0
   0.221 neg_r(thi)==0.9 and label is 0
   0.221 neg_r(even)==0.7000000000000001 and label is 0
   0.221 neg_r(__punc_ellp)==0.8 and label is 0
   0.221 neg_r(isnt)==1.0 and label is 0
   0.221 neg_r(look)==0.0 and label is 0
   0.221 neg_r(zoie)==0.0 and label is 0
   0.221 has(neb)==1 and label is 0
   0.221 has(treatment)==1 and label is 0
   0.221 has(number)==1 and label is 0
   0.221 has(thi)==1 and label is 0
   0.221 has(even)==1 and label is 0
   0.221 has(isnt)==1 and label is 0
   0.221 has(look)==1 and label is 0
   0.221 has(zoie)==1 and label is 0
  -0.218 neg_l(__punc_excl)==0.0 and label is 0
  -0.218 neg_r(__punc_excl)==0.0 and label is 0
  -0.218 has(__punc_excl)==1 and label is 0
   0.208 neg_l(ohh)==0.0 and label is 4
   0.208 neg_l(actual)==0.0 and label is 4
   0.208 neg_l(sick)==0.0 and label is 4
None
######################
Accuracy : 0.5
Confusion Matrix 
  | 0 4 |
--+-----+
0 |<.>1 |
4 | .<1>|
--+-----+
(row = reference; col = test)

length of train tweets 8
length of test tweets 2
  ==> Training (100 iterations)

      Iteration    Log Likelihood    Accuracy
      ---------------------------------------
             1          -0.69315        0.625
             2          -0.42282        1.000
             3          -0.30472        1.000
             4          -0.23820        1.000
             5          -0.19550        1.000
             6          -0.16576        1.000
             7          -0.14386        1.000
             8          -0.12707        1.000
             9          -0.11377        1.000
            10          -0.10300        1.000
            11          -0.09408        1.000
            12          -0.08658        1.000
            13          -0.08019        1.000
            14          -0.07467        1.000
            15          -0.06987        1.000
            16          -0.06564        1.000
            17          -0.06190        1.000
            18          -0.05855        1.000
            19          -0.05556        1.000
            20          -0.05285        1.000
            21          -0.05039        1.000
            22          -0.04815        1.000
            23          -0.04611        1.000
            24          -0.04422        1.000
            25          -0.04249        1.000
            26          -0.04089        1.000
            27          -0.03940        1.000
            28          -0.03802        1.000
            29          -0.03673        1.000
            30          -0.03553        1.000
            31          -0.03440        1.000
            32          -0.03334        1.000
            33          -0.03234        1.000
            34          -0.03141        1.000
            35          -0.03052        1.000
            36          -0.02968        1.000
            37          -0.02889        1.000
            38          -0.02814        1.000
            39          -0.02743        1.000
            40          -0.02675        1.000
            41          -0.02611        1.000
            42          -0.02549        1.000
            43          -0.02491        1.000
            44          -0.02435        1.000
            45          -0.02381        1.000
            46          -0.02330        1.000
            47          -0.02281        1.000
            48          -0.02234        1.000
            49          -0.02188        1.000
            50          -0.02145        1.000
            51          -0.02103        1.000
            52          -0.02063        1.000
            53          -0.02025        1.000
            54          -0.01988        1.000
            55          -0.01952        1.000
            56          -0.01917        1.000
            57          -0.01884        1.000
            58          -0.01852        1.000
            59          -0.01820        1.000
            60          -0.01790        1.000
            61          -0.01761        1.000
            62          -0.01733        1.000
            63          -0.01706        1.000
            64          -0.01679        1.000
            65          -0.01654        1.000
            66          -0.01629        1.000
            67          -0.01605        1.000
            68          -0.01581        1.000
            69          -0.01558        1.000
            70          -0.01536        1.000
            71          -0.01515        1.000
            72          -0.01494        1.000
            73          -0.01473        1.000
            74          -0.01454        1.000
            75          -0.01434        1.000
            76          -0.01416        1.000
            77          -0.01397        1.000
            78          -0.01380        1.000
            79          -0.01362        1.000
            80          -0.01345        1.000
            81          -0.01329        1.000
            82          -0.01313        1.000
            83          -0.01297        1.000
            84          -0.01281        1.000
            85          -0.01266        1.000
            86          -0.01252        1.000
            87          -0.01238        1.000
            88          -0.01224        1.000
            89          -0.01210        1.000
            90          -0.01196        1.000
            91          -0.01183        1.000
            92          -0.01171        1.000
            93          -0.01158        1.000
            94          -0.01146        1.000
            95          -0.01134        1.000
            96          -0.01122        1.000
            97          -0.01110        1.000
            98          -0.01099        1.000
            99          -0.01088        1.000
         Final          -0.01077        1.000
######################
1 Step Classifier :  RTEClassifier
Accuracy :  0.0
######################
   0.891 neg_l(50th)==0.0 and label is 4
   0.891 neg_l(follow)==0.0 and label is 4
   0.891 neg_r(50th)==0.0 and label is 4
   0.891 neg_r(follow)==0.0 and label is 4
   0.891 has(50th)==1 and label is 4
   0.891 has(follow)==1 and label is 4
   0.590 neg_l(still)==0.0 and label is 0
   0.590 neg_l(pour)==0.0 and label is 0
   0.590 neg_l(outsid)==0.0 and label is 0
   0.590 neg_r(__punc_ellp)==0.0 and label is 0
   0.590 neg_r(still)==0.0 and label is 0
   0.590 neg_r(pour)==0.0 and label is 0
   0.590 neg_r(outsid)==0.0 and label is 0
   0.590 has(still)==1 and label is 0
   0.590 has(pour)==1 and label is 0
   0.590 has(outsid)==1 and label is 0
   0.478 neg_l(proud)==0.0 and label is 4
   0.478 neg_l(best)==0.0 and label is 4
   0.478 neg_l(friend)==0.0 and label is 4
   0.478 neg_l(varsiti)==0.0 and label is 4
   0.478 neg_r(proud)==0.0 and label is 4
   0.478 neg_r(best)==0.0 and label is 4
   0.478 neg_r(friend)==0.0 and label is 4
   0.478 neg_r(varsiti)==0.0 and label is 4
   0.478 has(proud)==1 and label is 4
   0.478 has(best)==1 and label is 4
   0.478 has(friend)==1 and label is 4
   0.478 has(varsiti)==1 and label is 4
   0.332 neg_l(feel)==0.0 and label is 0
   0.332 neg_l(like)==0.0 and label is 0
   0.332 neg_l(go)==0.0 and label is 0
   0.332 neg_l(camp)==0.0 and label is 0
   0.332 neg_l(miss)==0.0 and label is 0
   0.332 neg_l(the)==0.0 and label is 0
   0.332 neg_l(outdoor)==0.0 and label is 0
   0.332 neg_r(feel)==0.0 and label is 0
   0.332 neg_r(like)==0.0 and label is 0
   0.332 neg_r(go)==0.0 and label is 0
   0.332 neg_r(camp)==0.0 and label is 0
   0.332 neg_r(miss)==0.0 and label is 0
   0.332 neg_r(the)==0.0 and label is 0
   0.332 neg_r(outdoor)==0.0 and label is 0
   0.332 has(feel)==1 and label is 0
   0.332 has(like)==1 and label is 0
   0.332 has(go)==1 and label is 0
   0.332 has(camp)==1 and label is 0
   0.332 has(miss)==1 and label is 0
   0.332 has(outdoor)==1 and label is 0
   0.316 neg_l(hear)==0.0 and label is 4
   0.316 neg_l(pina)==0.0 and label is 4
   0.316 neg_l(colada)==0.0 and label is 4
   0.316 neg_l(good)==0.0 and label is 4
   0.316 neg_l(for)==0.0 and label is 4
   0.316 neg_l(sore)==0.0 and label is 4
   0.316 neg_l(throat)==0.0 and label is 4
   0.316 neg_r(hear)==0.0 and label is 4
   0.316 neg_r(pina)==0.0 and label is 4
   0.316 neg_r(colada)==0.0 and label is 4
   0.316 neg_r(sore)==0.0 and label is 4
   0.316 neg_r(throat)==0.0 and label is 4
   0.316 has(hear)==1 and label is 4
   0.316 has(pina)==1 and label is 4
   0.316 has(colada)==1 and label is 4
   0.316 has(sore)==1 and label is 4
   0.316 has(throat)==1 and label is 4
   0.314 neg_l(__hndl)==0.0 and label is 4
   0.314 neg_r(__hndl)==0.0 and label is 4
   0.314 has(__hndl)==1 and label is 4
   0.312 neg_l(__punc_ellp)==0.0 and label is 0
   0.312 has(__punc_ellp)==1 and label is 0
   0.257 neg_l(__punc_excl)==0.0 and label is 4
   0.257 neg_r(__punc_excl)==0.0 and label is 4
   0.257 has(__punc_excl)==1 and label is 4
   0.220 neg_l(neb)==0.0 and label is 0
   0.220 neg_l(treatment)==0.0 and label is 0
   0.220 neg_l(number)==0.0 and label is 0
   0.220 neg_l(thi)==0.0 and label is 0
   0.220 neg_l(even)==0.0 and label is 0
   0.220 neg_l(isnt)==1.0 and label is 0
   0.220 neg_l(look)==0.9 and label is 0
   0.220 neg_l(good)==0.8 and label is 0
   0.220 neg_l(for)==0.7000000000000001 and label is 0
   0.220 neg_l(zoie)==0.6000000000000001 and label is 0
   0.220 neg_r(neb)==0.30000000000000016 and label is 0
   0.220 neg_r(treatment)==0.40000000000000013 and label is 0
   0.220 neg_r(number)==0.5000000000000001 and label is 0
   0.220 neg_r(thi)==0.9 and label is 0
   0.220 neg_r(even)==0.7000000000000001 and label is 0
   0.220 neg_r(__punc_ellp)==0.8 and label is 0
   0.220 neg_r(isnt)==1.0 and label is 0
   0.220 neg_r(look)==0.0 and label is 0
   0.220 neg_r(zoie)==0.0 and label is 0
   0.220 has(neb)==1 and label is 0
   0.220 has(treatment)==1 and label is 0
   0.220 has(number)==1 and label is 0
   0.220 has(thi)==1 and label is 0
   0.220 has(even)==1 and label is 0
   0.220 has(isnt)==1 and label is 0
   0.220 has(look)==1 and label is 0
   0.220 has(zoie)==1 and label is 0
None
######################
Accuracy : 0.0
Confusion Matrix 
  | 0 4 |
--+-----+
0 |<.>1 |
4 | 1<.>|
--+-----+
(row = reference; col = test)

length of train tweets 8
length of test tweets 2
  ==> Training (100 iterations)

      Iteration    Log Likelihood    Accuracy
      ---------------------------------------
             1          -0.69315        0.500
             2          -0.44196        1.000
             3          -0.32475        1.000
             4          -0.25654        1.000
             5          -0.21192        1.000
             6          -0.18046        1.000
             7          -0.15711        1.000
             8          -0.13908        1.000
             9          -0.12476        1.000
            10          -0.11310        1.000
            11          -0.10342        1.000
            12          -0.09527        1.000
            13          -0.08830        1.000
            14          -0.08228        1.000
            15          -0.07703        1.000
            16          -0.07241        1.000
            17          -0.06830        1.000
            18          -0.06464        1.000
            19          -0.06135        1.000
            20          -0.05838        1.000
            21          -0.05568        1.000
            22          -0.05322        1.000
            23          -0.05097        1.000
            24          -0.04890        1.000
            25          -0.04699        1.000
            26          -0.04522        1.000
            27          -0.04358        1.000
            28          -0.04206        1.000
            29          -0.04064        1.000
            30          -0.03931        1.000
            31          -0.03807        1.000
            32          -0.03690        1.000
            33          -0.03580        1.000
            34          -0.03477        1.000
            35          -0.03379        1.000
            36          -0.03287        1.000
            37          -0.03199        1.000
            38          -0.03116        1.000
            39          -0.03037        1.000
            40          -0.02963        1.000
            41          -0.02891        1.000
            42          -0.02823        1.000
            43          -0.02759        1.000
            44          -0.02697        1.000
            45          -0.02637        1.000
            46          -0.02581        1.000
            47          -0.02527        1.000
            48          -0.02475        1.000
            49          -0.02425        1.000
            50          -0.02377        1.000
            51          -0.02330        1.000
            52          -0.02286        1.000
            53          -0.02243        1.000
            54          -0.02202        1.000
            55          -0.02163        1.000
            56          -0.02124        1.000
            57          -0.02087        1.000
            58          -0.02052        1.000
            59          -0.02017        1.000
            60          -0.01984        1.000
            61          -0.01952        1.000
            62          -0.01921        1.000
            63          -0.01890        1.000
            64          -0.01861        1.000
            65          -0.01833        1.000
            66          -0.01805        1.000
            67          -0.01778        1.000
            68          -0.01752        1.000
            69          -0.01727        1.000
            70          -0.01703        1.000
            71          -0.01679        1.000
            72          -0.01656        1.000
            73          -0.01633        1.000
            74          -0.01611        1.000
            75          -0.01590        1.000
            76          -0.01569        1.000
            77          -0.01549        1.000
            78          -0.01529        1.000
            79          -0.01510        1.000
            80          -0.01491        1.000
            81          -0.01473        1.000
            82          -0.01455        1.000
            83          -0.01438        1.000
            84          -0.01421        1.000
            85          -0.01404        1.000
            86          -0.01388        1.000
            87          -0.01372        1.000
            88          -0.01356        1.000
            89          -0.01341        1.000
            90          -0.01326        1.000
            91          -0.01312        1.000
            92          -0.01298        1.000
            93          -0.01284        1.000
            94          -0.01270        1.000
            95          -0.01257        1.000
            96          -0.01244        1.000
            97          -0.01231        1.000
            98          -0.01219        1.000
            99          -0.01206        1.000
         Final          -0.01194        1.000
######################
1 Step Classifier :  RTEClassifier
Accuracy :  0.5
######################
   0.630 neg_l(still)==0.0 and label is 0
   0.630 neg_l(pour)==0.0 and label is 0
   0.630 neg_l(outsid)==0.0 and label is 0
   0.630 neg_r(still)==0.0 and label is 0
   0.630 neg_r(pour)==0.0 and label is 0
   0.630 neg_r(outsid)==0.0 and label is 0
   0.630 has(still)==1 and label is 0
   0.630 has(pour)==1 and label is 0
   0.630 has(outsid)==1 and label is 0
   0.382 neg_l(like)==0.0 and label is 0
   0.382 neg_l(go)==0.0 and label is 0
   0.382 neg_l(camp)==0.0 and label is 0
   0.382 neg_l(miss)==0.0 and label is 0
   0.382 neg_l(the)==0.0 and label is 0
   0.382 neg_l(outdoor)==0.0 and label is 0
   0.382 neg_r(like)==0.0 and label is 0
   0.382 neg_r(go)==0.0 and label is 0
   0.382 neg_r(camp)==0.0 and label is 0
   0.382 neg_r(miss)==0.0 and label is 0
   0.382 neg_r(the)==0.0 and label is 0
   0.382 neg_r(outdoor)==0.0 and label is 0
   0.382 has(like)==1 and label is 0
   0.382 has(go)==1 and label is 0
   0.382 has(camp)==1 and label is 0
   0.382 has(miss)==1 and label is 0
   0.382 has(outdoor)==1 and label is 0
   0.356 neg_l(pina)==0.0 and label is 4
   0.356 neg_l(colada)==0.0 and label is 4
   0.356 neg_l(good)==0.0 and label is 4
   0.356 neg_l(for)==0.0 and label is 4
   0.356 neg_l(sore)==0.0 and label is 4
   0.356 neg_l(throat)==0.0 and label is 4
   0.356 neg_r(pina)==0.0 and label is 4
   0.356 neg_r(colada)==0.0 and label is 4
   0.356 neg_r(sore)==0.0 and label is 4
   0.356 neg_r(throat)==0.0 and label is 4
   0.356 has(pina)==1 and label is 4
   0.356 has(colada)==1 and label is 4
   0.356 has(sore)==1 and label is 4
   0.356 has(throat)==1 and label is 4
   0.298 neg_l(hate)==0.0 and label is 0
   0.298 neg_l(wierd)==0.0 and label is 0
   0.298 neg_l(unknown)==0.0 and label is 0
   0.298 neg_l(thing)==0.0 and label is 0
   0.298 neg_l(move)==0.0 and label is 0
   0.298 neg_l(around)==0.0 and label is 0
   0.298 neg_l(night)==0.0 and label is 0
   0.298 neg_r(hate)==0.0 and label is 0
   0.298 neg_r(wierd)==0.0 and label is 0
   0.298 neg_r(unknown)==0.0 and label is 0
   0.298 neg_r(thing)==0.0 and label is 0
   0.298 neg_r(move)==0.0 and label is 0
   0.298 neg_r(around)==0.0 and label is 0
   0.298 neg_r(night)==0.0 and label is 0
   0.298 has(hate)==1 and label is 0
   0.298 has(wierd)==1 and label is 0
   0.298 has(unknown)==1 and label is 0
   0.298 has(thing)==1 and label is 0
   0.298 has(move)==1 and label is 0
   0.298 has(around)==1 and label is 0
   0.298 has(night)==1 and label is 0
   0.243 neg_l(__hndl)==0.0 and label is 4
   0.243 neg_r(__hndl)==0.0 and label is 4
   0.243 has(__hndl)==1 and label is 4
  -0.231 neg_l(__punc_ellp)==0.0 and label is 4
  -0.231 has(__punc_ellp)==1 and label is 4
   0.227 neg_l(ohh)==0.0 and label is 4
   0.227 neg_l(actual)==0.0 and label is 4
   0.227 neg_l(sick)==0.0 and label is 4
   0.227 neg_l(__punc_qu)==0.0 and label is 4
   0.227 neg_l(that)==0.0 and label is 4
   0.227 neg_l(sux)==0.0 and label is 4
   0.227 neg_l(hope)==0.0 and label is 4
   0.227 neg_l(better)==0.0 and label is 4
   0.227 neg_l(soon)==0.0 and label is 4
   0.227 neg_r(ohh)==0.0 and label is 4
   0.227 neg_r(actual)==0.0 and label is 4
   0.227 neg_r(sick)==0.0 and label is 4
   0.227 neg_r(__punc_qu)==0.0 and label is 4
   0.227 neg_r(that)==0.0 and label is 4
   0.227 neg_r(sux)==0.0 and label is 4
   0.227 neg_r(hope)==0.0 and label is 4
   0.227 neg_r(better)==0.0 and label is 4
   0.227 neg_r(soon)==0.0 and label is 4
   0.227 pos(better)==1 and label is 4
   0.227 has(ohh)==1 and label is 4
   0.227 has(actual)==1 and label is 4
   0.227 has(sick)==1 and label is 4
   0.227 has(__punc_qu)==1 and label is 4
   0.227 has(sux)==1 and label is 4
   0.227 has(hope)==1 and label is 4
   0.227 has(better)==1 and label is 4
   0.227 has(soon)==1 and label is 4
   0.222 neg_l(neb)==0.0 and label is 0
   0.222 neg_l(treatment)==0.0 and label is 0
   0.222 neg_l(number)==0.0 and label is 0
   0.222 neg_l(thi)==0.0 and label is 0
   0.222 neg_l(even)==0.0 and label is 0
   0.222 neg_l(isnt)==1.0 and label is 0
   0.222 neg_l(look)==0.9 and label is 0
None
######################
Accuracy : 0.5
Confusion Matrix 
  | 0 4 |
--+-----+
0 |<.>. |
4 | 1<1>|
--+-----+
(row = reference; col = test)

length of train tweets 8
length of test tweets 2
  ==> Training (100 iterations)

      Iteration    Log Likelihood    Accuracy
      ---------------------------------------
             1          -0.69315        0.500
             2          -0.43414        1.000
             3          -0.31701        1.000
             4          -0.24961        1.000
             5          -0.20579        1.000
             6          -0.17502        1.000
             7          -0.15223        1.000
             8          -0.13467        1.000
             9          -0.12074        1.000
            10          -0.10941        1.000
            11          -0.10002        1.000
            12          -0.09211        1.000
            13          -0.08536        1.000
            14          -0.07952        1.000
            15          -0.07444        1.000
            16          -0.06996        1.000
            17          -0.06599        1.000
            18          -0.06244        1.000
            19          -0.05926        1.000
            20          -0.05638        1.000
            21          -0.05377        1.000
            22          -0.05139        1.000
            23          -0.04922        1.000
            24          -0.04721        1.000
            25          -0.04537        1.000
            26          -0.04366        1.000
            27          -0.04208        1.000
            28          -0.04061        1.000
            29          -0.03923        1.000
            30          -0.03795        1.000
            31          -0.03675        1.000
            32          -0.03562        1.000
            33          -0.03456        1.000
            34          -0.03356        1.000
            35          -0.03262        1.000
            36          -0.03172        1.000
            37          -0.03088        1.000
            38          -0.03008        1.000
            39          -0.02932        1.000
            40          -0.02859        1.000
            41          -0.02791        1.000
            42          -0.02725        1.000
            43          -0.02662        1.000
            44          -0.02603        1.000
            45          -0.02546        1.000
            46          -0.02491        1.000
            47          -0.02438        1.000
            48          -0.02388        1.000
            49          -0.02340        1.000
            50          -0.02294        1.000
            51          -0.02249        1.000
            52          -0.02206        1.000
            53          -0.02165        1.000
            54          -0.02125        1.000
            55          -0.02087        1.000
            56          -0.02050        1.000
            57          -0.02015        1.000
            58          -0.01980        1.000
            59          -0.01947        1.000
            60          -0.01915        1.000
            61          -0.01884        1.000
            62          -0.01853        1.000
            63          -0.01824        1.000
            64          -0.01796        1.000
            65          -0.01769        1.000
            66          -0.01742        1.000
            67          -0.01716        1.000
            68          -0.01691        1.000
            69          -0.01667        1.000
            70          -0.01643        1.000
            71          -0.01620        1.000
            72          -0.01598        1.000
            73          -0.01576        1.000
            74          -0.01555        1.000
            75          -0.01534        1.000
            76          -0.01514        1.000
            77          -0.01495        1.000
            78          -0.01476        1.000
            79          -0.01457        1.000
            80          -0.01439        1.000
            81          -0.01421        1.000
            82          -0.01404        1.000
            83          -0.01387        1.000
            84          -0.01371        1.000
            85          -0.01355        1.000
            86          -0.01339        1.000
            87          -0.01324        1.000
            88          -0.01309        1.000
            89          -0.01294        1.000
            90          -0.01280        1.000
            91          -0.01266        1.000
            92          -0.01252        1.000
            93          -0.01239        1.000
            94          -0.01226        1.000
            95          -0.01213        1.000
            96          -0.01200        1.000
            97          -0.01188        1.000
            98          -0.01176        1.000
            99          -0.01164        1.000
         Final          -0.01153        1.000
######################
1 Step Classifier :  RTEClassifier
Accuracy :  0.5
######################
   0.905 neg_l(50th)==0.0 and label is 4
   0.905 neg_l(follow)==0.0 and label is 4
   0.905 neg_r(50th)==0.0 and label is 4
   0.905 neg_r(follow)==0.0 and label is 4
   0.905 has(50th)==1 and label is 4
   0.905 has(follow)==1 and label is 4
   0.633 neg_l(still)==0.0 and label is 0
   0.633 neg_l(pour)==0.0 and label is 0
   0.633 neg_l(outsid)==0.0 and label is 0
   0.633 neg_r(still)==0.0 and label is 0
   0.633 neg_r(pour)==0.0 and label is 0
   0.633 neg_r(outsid)==0.0 and label is 0
   0.633 has(still)==1 and label is 0
   0.633 has(pour)==1 and label is 0
   0.633 has(outsid)==1 and label is 0
   0.519 neg_l(proud)==0.0 and label is 4
   0.519 neg_l(best)==0.0 and label is 4
   0.519 neg_l(friend)==0.0 and label is 4
   0.519 neg_l(varsiti)==0.0 and label is 4
   0.519 neg_r(proud)==0.0 and label is 4
   0.519 neg_r(best)==0.0 and label is 4
   0.519 neg_r(friend)==0.0 and label is 4
   0.519 neg_r(varsiti)==0.0 and label is 4
   0.519 has(proud)==1 and label is 4
   0.519 has(best)==1 and label is 4
   0.519 has(friend)==1 and label is 4
   0.519 has(varsiti)==1 and label is 4
   0.381 neg_l(like)==0.0 and label is 0
   0.381 neg_l(go)==0.0 and label is 0
   0.381 neg_l(camp)==0.0 and label is 0
   0.381 neg_l(miss)==0.0 and label is 0
   0.381 neg_l(the)==0.0 and label is 0
   0.381 neg_l(outdoor)==0.0 and label is 0
   0.381 neg_r(like)==0.0 and label is 0
   0.381 neg_r(go)==0.0 and label is 0
   0.381 neg_r(camp)==0.0 and label is 0
   0.381 neg_r(miss)==0.0 and label is 0
   0.381 neg_r(the)==0.0 and label is 0
   0.381 neg_r(outdoor)==0.0 and label is 0
   0.381 has(like)==1 and label is 0
   0.381 has(go)==1 and label is 0
   0.381 has(camp)==1 and label is 0
   0.381 has(miss)==1 and label is 0
   0.381 has(outdoor)==1 and label is 0
   0.276 neg_l(__hndl)==0.0 and label is 4
   0.276 neg_r(__hndl)==0.0 and label is 4
   0.276 has(__hndl)==1 and label is 4
   0.273 neg_l(hate)==0.0 and label is 0
   0.273 neg_l(hear)==0.0 and label is 0
   0.273 neg_l(wierd)==0.0 and label is 0
   0.273 neg_l(unknown)==0.0 and label is 0
   0.273 neg_l(thing)==0.0 and label is 0
   0.273 neg_l(move)==0.0 and label is 0
   0.273 neg_l(around)==0.0 and label is 0
   0.273 neg_l(night)==0.0 and label is 0
   0.273 neg_r(hate)==0.0 and label is 0
   0.273 neg_r(hear)==0.0 and label is 0
   0.273 neg_r(wierd)==0.0 and label is 0
   0.273 neg_r(unknown)==0.0 and label is 0
   0.273 neg_r(thing)==0.0 and label is 0
   0.273 neg_r(move)==0.0 and label is 0
   0.273 neg_r(around)==0.0 and label is 0
   0.273 neg_r(night)==0.0 and label is 0
   0.273 has(hate)==1 and label is 0
   0.273 has(hear)==1 and label is 0
   0.273 has(wierd)==1 and label is 0
   0.273 has(unknown)==1 and label is 0
   0.273 has(thing)==1 and label is 0
   0.273 has(move)==1 and label is 0
   0.273 has(around)==1 and label is 0
   0.273 has(night)==1 and label is 0
   0.224 neg_l(ohh)==0.0 and label is 4
   0.224 neg_l(actual)==0.0 and label is 4
   0.224 neg_l(sick)==0.0 and label is 4
   0.224 neg_l(__punc_qu)==0.0 and label is 4
   0.224 neg_l(that)==0.0 and label is 4
   0.224 neg_l(sux)==0.0 and label is 4
   0.224 neg_l(hope)==0.0 and label is 4
   0.224 neg_l(better)==0.0 and label is 4
   0.224 neg_l(soon)==0.0 and label is 4
   0.224 neg_r(ohh)==0.0 and label is 4
   0.224 neg_r(actual)==0.0 and label is 4
   0.224 neg_r(sick)==0.0 and label is 4
   0.224 neg_r(__punc_qu)==0.0 and label is 4
   0.224 neg_r(that)==0.0 and label is 4
   0.224 neg_r(sux)==0.0 and label is 4
   0.224 neg_r(hope)==0.0 and label is 4
   0.224 neg_r(better)==0.0 and label is 4
   0.224 neg_r(soon)==0.0 and label is 4
   0.224 pos(better)==1 and label is 4
   0.224 has(ohh)==1 and label is 4
   0.224 has(actual)==1 and label is 4
   0.224 has(sick)==1 and label is 4
   0.224 has(__punc_qu)==1 and label is 4
   0.224 has(sux)==1 and label is 4
   0.224 has(hope)==1 and label is 4
   0.224 has(better)==1 and label is 4
   0.224 has(soon)==1 and label is 4
  -0.222 neg_l(__punc_ellp)==0.0 and label is 4
  -0.222 has(__punc_ellp)==1 and label is 4
None
######################
Accuracy : 0.5
Confusion Matrix 
  | 0 4 |
--+-----+
0 |<.>. |
4 | 1<1>|
--+-----+
(row = reference; col = test)

length of train tweets 8
length of test tweets 2
  ==> Training (100 iterations)

      Iteration    Log Likelihood    Accuracy
      ---------------------------------------
             1          -0.69315        0.750
             2          -0.42946        1.000
             3          -0.31325        1.000
             4          -0.24655        1.000
             5          -0.20322        1.000
             6          -0.17281        1.000
             7          -0.15029        1.000
             8          -0.13295        1.000
             9          -0.11918        1.000
            10          -0.10800        1.000
            11          -0.09872        1.000
            12          -0.09092        1.000
            13          -0.08425        1.000
            14          -0.07849        1.000
            15          -0.07347        1.000
            16          -0.06905        1.000
            17          -0.06513        1.000
            18          -0.06163        1.000
            19          -0.05849        1.000
            20          -0.05565        1.000
            21          -0.05307        1.000
            22          -0.05072        1.000
            23          -0.04857        1.000
            24          -0.04660        1.000
            25          -0.04478        1.000
            26          -0.04309        1.000
            27          -0.04153        1.000
            28          -0.04008        1.000
            29          -0.03872        1.000
            30          -0.03746        1.000
            31          -0.03627        1.000
            32          -0.03516        1.000
            33          -0.03411        1.000
            34          -0.03312        1.000
            35          -0.03219        1.000
            36          -0.03131        1.000
            37          -0.03048        1.000
            38          -0.02969        1.000
            39          -0.02894        1.000
            40          -0.02822        1.000
            41          -0.02754        1.000
            42          -0.02690        1.000
            43          -0.02628        1.000
            44          -0.02569        1.000
            45          -0.02512        1.000
            46          -0.02458        1.000
            47          -0.02407        1.000
            48          -0.02357        1.000
            49          -0.02310        1.000
            50          -0.02264        1.000
            51          -0.02220        1.000
            52          -0.02178        1.000
            53          -0.02137        1.000
            54          -0.02098        1.000
            55          -0.02060        1.000
            56          -0.02024        1.000
            57          -0.01988        1.000
            58          -0.01954        1.000
            59          -0.01922        1.000
            60          -0.01890        1.000
            61          -0.01859        1.000
            62          -0.01829        1.000
            63          -0.01801        1.000
            64          -0.01773        1.000
            65          -0.01746        1.000
            66          -0.01719        1.000
            67          -0.01694        1.000
            68          -0.01669        1.000
            69          -0.01645        1.000
            70          -0.01622        1.000
            71          -0.01599        1.000
            72          -0.01577        1.000
            73          -0.01556        1.000
            74          -0.01535        1.000
            75          -0.01514        1.000
            76          -0.01495        1.000
            77          -0.01475        1.000
            78          -0.01457        1.000
            79          -0.01438        1.000
            80          -0.01420        1.000
            81          -0.01403        1.000
            82          -0.01386        1.000
            83          -0.01369        1.000
            84          -0.01353        1.000
            85          -0.01337        1.000
            86          -0.01322        1.000
            87          -0.01307        1.000
            88          -0.01292        1.000
            89          -0.01278        1.000
            90          -0.01263        1.000
            91          -0.01250        1.000
            92          -0.01236        1.000
            93          -0.01223        1.000
            94          -0.01210        1.000
            95          -0.01197        1.000
            96          -0.01185        1.000
            97          -0.01173        1.000
            98          -0.01161        1.000
            99          -0.01149        1.000
         Final          -0.01138        1.000
######################
1 Step Classifier :  RTEClassifier
Accuracy :  0.0
######################
   0.905 neg_l(50th)==0.0 and label is 4
   0.905 neg_l(follow)==0.0 and label is 4
   0.905 neg_r(50th)==0.0 and label is 4
   0.905 neg_r(follow)==0.0 and label is 4
   0.905 has(50th)==1 and label is 4
   0.905 has(follow)==1 and label is 4
   0.464 neg_l(proud)==0.0 and label is 4
   0.464 neg_l(best)==0.0 and label is 4
   0.464 neg_l(friend)==0.0 and label is 4
   0.464 neg_l(varsiti)==0.0 and label is 4
   0.464 neg_r(proud)==0.0 and label is 4
   0.464 neg_r(best)==0.0 and label is 4
   0.464 neg_r(friend)==0.0 and label is 4
   0.464 neg_r(varsiti)==0.0 and label is 4
   0.464 has(proud)==1 and label is 4
   0.464 has(best)==1 and label is 4
   0.464 has(friend)==1 and label is 4
   0.464 has(varsiti)==1 and label is 4
   0.372 neg_l(like)==0.0 and label is 0
   0.372 neg_l(go)==0.0 and label is 0
   0.372 neg_l(camp)==0.0 and label is 0
   0.372 neg_l(miss)==0.0 and label is 0
   0.372 neg_l(the)==0.0 and label is 0
   0.372 neg_l(outdoor)==0.0 and label is 0
   0.372 neg_r(like)==0.0 and label is 0
   0.372 neg_r(go)==0.0 and label is 0
   0.372 neg_r(camp)==0.0 and label is 0
   0.372 neg_r(miss)==0.0 and label is 0
   0.372 neg_r(the)==0.0 and label is 0
   0.372 neg_r(outdoor)==0.0 and label is 0
   0.372 has(like)==1 and label is 0
   0.372 has(go)==1 and label is 0
   0.372 has(camp)==1 and label is 0
   0.372 has(miss)==1 and label is 0
   0.372 has(outdoor)==1 and label is 0
   0.326 neg_l(hate)==0.0 and label is 0
   0.326 neg_l(wierd)==0.0 and label is 0
   0.326 neg_l(unknown)==0.0 and label is 0
   0.326 neg_l(thing)==0.0 and label is 0
   0.326 neg_l(move)==0.0 and label is 0
   0.326 neg_l(around)==0.0 and label is 0
   0.326 neg_l(night)==0.0 and label is 0
   0.326 neg_r(hate)==0.0 and label is 0
   0.326 neg_r(wierd)==0.0 and label is 0
   0.326 neg_r(unknown)==0.0 and label is 0
   0.326 neg_r(thing)==0.0 and label is 0
   0.326 neg_r(move)==0.0 and label is 0
   0.326 neg_r(around)==0.0 and label is 0
   0.326 neg_r(night)==0.0 and label is 0
   0.326 has(hate)==1 and label is 0
   0.326 has(wierd)==1 and label is 0
   0.326 has(unknown)==1 and label is 0
   0.326 has(thing)==1 and label is 0
   0.326 has(move)==1 and label is 0
   0.326 has(around)==1 and label is 0
   0.326 has(night)==1 and label is 0
   0.321 neg_l(pina)==0.0 and label is 4
   0.321 neg_l(colada)==0.0 and label is 4
   0.321 neg_l(good)==0.0 and label is 4
   0.321 neg_l(for)==0.0 and label is 4
   0.321 neg_l(sore)==0.0 and label is 4
   0.321 neg_l(throat)==0.0 and label is 4
   0.321 neg_r(pina)==0.0 and label is 4
   0.321 neg_r(colada)==0.0 and label is 4
   0.321 neg_r(good)==0.0 and label is 4
   0.321 neg_r(for)==0.0 and label is 4
   0.321 neg_r(sore)==0.0 and label is 4
   0.321 neg_r(throat)==0.0 and label is 4
   0.321 pos(good)==1 and label is 4
   0.321 has(pina)==1 and label is 4
   0.321 has(colada)==1 and label is 4
   0.321 has(good)==1 and label is 4
   0.321 has(sore)==1 and label is 4
   0.321 has(throat)==1 and label is 4
   0.276 neg_l(__hndl)==0.0 and label is 4
   0.276 neg_r(__hndl)==0.0 and label is 4
   0.276 has(__hndl)==1 and label is 4
  -0.222 neg_l(__punc_excl)==0.0 and label is 0
  -0.222 neg_r(__punc_excl)==0.0 and label is 0
  -0.222 has(__punc_excl)==1 and label is 0
   0.194 neg_l(ohh)==0.0 and label is 4
   0.194 neg_l(actual)==0.0 and label is 4
   0.194 neg_l(sick)==0.0 and label is 4
   0.194 neg_l(__punc_qu)==0.0 and label is 4
   0.194 neg_l(that)==0.0 and label is 4
   0.194 neg_l(sux)==0.0 and label is 4
   0.194 neg_l(__punc_ellp)==0.0 and label is 4
   0.194 neg_l(hope)==0.0 and label is 4
   0.194 neg_l(better)==0.0 and label is 4
   0.194 neg_l(soon)==0.0 and label is 4
   0.194 neg_r(ohh)==0.0 and label is 4
   0.194 neg_r(actual)==0.0 and label is 4
   0.194 neg_r(sick)==0.0 and label is 4
   0.194 neg_r(__punc_qu)==0.0 and label is 4
   0.194 neg_r(that)==0.0 and label is 4
   0.194 neg_r(sux)==0.0 and label is 4
   0.194 neg_r(__punc_ellp)==0.0 and label is 4
   0.194 neg_r(hope)==0.0 and label is 4
   0.194 neg_r(better)==0.0 and label is 4
   0.194 neg_r(soon)==0.0 and label is 4
None
######################
Accuracy : 0.0
Confusion Matrix 
  | 0 4 |
--+-----+
0 |<.>2 |
4 | .<.>|
--+-----+
(row = reference; col = test)

Accuracies: [0.5, 0.0, 0.5, 0.5, 0.0]
Average Accuracy: 0.3
